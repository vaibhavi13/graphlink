{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "651a3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import community as comm\n",
    "import community.community_louvain\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b019c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph():\n",
    "    #graphfile = 'facebook_combined.txt'\n",
    "    graphfile = 'facebook_combined.txt'\n",
    "    print(\"data file used is \"+ graphfile)\n",
    "    # labelfile = 'facebook_combined.nodes.labels'\n",
    "    G = nx.read_edgelist(graphfile, nodetype=None)\n",
    "    G = G.to_directed()\n",
    "    print(\"Number of nodes: \", G.number_of_nodes())\n",
    "    print(\"Number of edges: \", G.number_of_edges())\n",
    "    return G\n",
    "\n",
    "def get_embedding(G, walks, embed_size=128, window_size=5, workers=3, iter=5, **kwargs):\n",
    "    kwargs[\"sentences\"] = walks\n",
    "    kwargs[\"min_count\"] = kwargs.get(\"min_count\", 0)\n",
    "    kwargs[\"vector_size\"] = embed_size\n",
    "    kwargs[\"sg\"] = 1  # skip gram\n",
    "    kwargs[\"hs\"] = 1  # deepwalk use Hierarchical Softmax\n",
    "    kwargs[\"workers\"] = workers\n",
    "    kwargs[\"window\"] = window_size\n",
    "    kwargs[\"epochs\"] = iter\n",
    "\n",
    "    print(\"Learning embedding vectors...\")\n",
    "    model = Word2Vec(**kwargs)\n",
    "    print(\"Learning embedding vectors done!\")\n",
    "    print(\"model is \\n\")\n",
    "    print(model)\n",
    "    embeddings = {}\n",
    "    for word in G.nodes():\n",
    "        embeddings[word] = model.wv[word]\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def deepwalk_walks(G, num_walks, walk_length,):\n",
    "        nodes = G.nodes()\n",
    "        walks = []\n",
    "        for _ in range(num_walks):\n",
    "            for v in nodes:\n",
    "                walk = [v]\n",
    "                while len(walk) < walk_length:\n",
    "                    cur = walk[-1]\n",
    "                    cur_nbrs = list(G.neighbors(cur))\n",
    "                    if len(cur_nbrs) > 0:\n",
    "                        walk.append(random.choice(cur_nbrs))\n",
    "                    else:\n",
    "                        break\n",
    "                walks.append(walk)\n",
    "        return walks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0345140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file used is facebook_combined.txt\n",
      "Number of nodes:  4039\n",
      "Number of edges:  176468\n",
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n",
      "model is \n",
      "\n",
      "Word2Vec(vocab=4039, vector_size=128, alpha=0.025)\n",
      "shape of points is (4038, 128)\n",
      "\n",
      "Starting kmeans...\n",
      "\n",
      "Finished kmeans...\n",
      "Execution time: 1.356048822402954 seconds\n"
     ]
    }
   ],
   "source": [
    "G = load_graph()\n",
    "l = 1\n",
    "walks_deepwalk = deepwalk_walks(G, walk_length=l, num_walks=80)\n",
    "embeddings_deepwalk = get_embedding(G,walks_deepwalk)\n",
    "G1 = G.to_undirected()\n",
    "\n",
    "points = [[0] for i in range(G1.number_of_nodes()-1)]\n",
    "for i in range(0, G1.number_of_nodes()-1):\n",
    "    points[i] = embeddings_deepwalk[str(i+1)]\n",
    "points = np.array(points)\n",
    "\n",
    "print(\"shape of points is \"+ str(points.shape))\n",
    "\n",
    "\n",
    "#modularity_scores = cluster_eval(G1, embeddings_deepwalk)\n",
    "#points = np.array([ [9.0, 10.0], [1000, 9000],[1,2],[2,1],[2,2],[9,9],[1000,8000]])\n",
    "#k = 3\n",
    "\n",
    "max_iters = 10\n",
    "NOC = 100\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting kmeans...\")\n",
    "\n",
    "for k in range(99, NOC):\n",
    "    clusters = KMeans(n_clusters=k, random_state=0).fit(points)\n",
    "   \n",
    "\n",
    "print(\"\\nFinished kmeans...\")\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Execution time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef94879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
